<!doctype html><html lang=en-us><head><script type=application/javascript>var doNotTrack=!1;doNotTrack||(window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-109890414-1","auto"),ga("send","pageview"))</script><script async src=https://www.google-analytics.com/analytics.js></script><title>defining ai | airport people</title><meta name=title content="defining ai | airport people"><meta charset=utf-8><meta http-equiv=x-ua-compatible content="chrome=1"><meta name=HandheldFriendly content="True"><meta name=MobileOptimized content="320"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer-when-downgrade"><base href=https://airport-people.com><meta name=description content="ai/not"><meta name=author content="Leon Johnson"><meta property="og:title" content="defining ai | airport people"><meta property="og:type" content="website"><meta property="og:url" content="https://airport-people.com"><meta name=og:description content="ai/not"><link rel=icon type=image/png sizes=16x16 href=https://airport-people.com/images/slash.ico><meta name=theme-color content="#FFF"><link rel=canonical href=https://airport-people.com/blog/20201212/><link rel=stylesheet href=https://airport-people.com/style.8b2d8a73ae9931c8ce21b892fd6eb273f4da6b884e429b5485fcdc01e5e2a043.css type=text/css><style>.lazyload{opacity:.0001}.logo .lazyload{min-width:10em}</style><script src=https://airport-people.com/js/vendor/lazysizes.min.js async></script>
<link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css><link href=https://fonts.cdnfonts.com/css/cmu-serif rel=stylesheet><link href=http://fonts.cdnfonts.com/css/cnc-vector rel=stylesheet><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css integrity=sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js integrity=sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4 crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js integrity=sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa crossorigin=anonymous></script>
<script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script><link rel=stylesheet href=https://unpkg.com/littlefoot/dist/littlefoot.css></head><body><nav class="row middle-xs center-xs"><div class="col-xs-6 col-sm-1 logo"><a href=https://airport-people.com/#><img data-src=https://airport-people.com/images/braille_small.svg class=lazyload lazyload=on alt="airport people"></a></div><div class="col-xs-3 col-sm-2"><h3><a href=https://airport-people.com/#about>ab°ut</a></h3></div><div class="col-xs-3 col-sm-2"><h3><a href=https://airport-people.com/#work>mus|c</a></h3></div><div class="col-xs-3 col-sm-2"><h3><a href=https://airport-people.com/#blog>thoug/ts</a></h3></div><div class="col-xs-3 col-sm-2"><h3><a href=https://airport-people.com/#contact>e_mail</a></h3></div><div class="col-xs-6 col-sm-1 nav-toggle"><a href class=nav-icon onclick=return!1><p class=lazyload lazyload=on alt="Open Menu">/ / /</p><p class=lazyload lazyload=on alt="Close Menu" style=display:none>\ \ \</p></a></div></nav><section class="nav-full row middle-xs center-xs"><div class=col-xs-12><div class="row middle-xs center-xs"><div class=col-xs-12><h1><a href=https://airport-people.com/#about>ab°ut</a></h1></div><div class=col-xs-12><h1><a href=https://airport-people.com/#work>mus|c</a></h1></div><div class=col-xs-12><h1><a href=https://airport-people.com/#blog>thoug/ts</a></h1></div><div class=col-xs-12><h1><a href=https://airport-people.com/#contact>e_mail</a></h1></div></div></div></section><main><section class=container><section class=content><h1>defining ai</h1><div class=sub-header>December 12, 2020 · ai/not</div><article class=entry-content><h1 id=introduction>introduction</h1><p>In the summer of 1956, Dartmouth College held its first Summer Research Project on Artificial Intelligence to discuss developments in a new field called (and there coined) “artificial intelligence.” But, the idea of thinking mechanical agents was made clear in earlier texts such as Alan Turing’s seminal work Computing Machinery and Intelligence (1950), and even as early as 1637, when Descartes implied a requirement for some test by which we may distinguish between humans and machines that act human-like.<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup> Even further, Rabbi Daniel Nevins<sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup> illustrates how the ancient folkloric notion of a golem can be interpreted as a theoretical creature with some sort of artificial (limited) intelligence. Ostensibly, AI is an old compelling idea, and it goes by many names and forms, so pinning down a useful comprehensive definition is an increasingly difficult task.</p><h1 id=colloquially>colloquially</h1><p>Today, the phrase “artificial intelligence” (AI) is used in so many ways that it is all but rendered meaningless. It is used to describe image recognition algorithms, text generation, chat-bots, linear regression, artificial neural networks, topic models, etc. Russell & Norvig use a goal-based definition,<sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup> implying AI is the &ldquo;field that aims at building&rdquo; systems which think (or act) like humans, or systems which think (or act) rationally. Often, the tech and robotics industries use the term to inculcate in their users a sense that their product is accomplishing something technologically sexy. But, I for one am not convinced we are ready to define artificial intelligence any more than we are equipped to define intelligence itself. What is intelligence?<sup id=fnref:4><a href=#fn:4 class=footnote-ref role=doc-noteref>4</a></sup> Is intelligence a purely human trait, or is it universal? Is limited intelligence (e.g., stupidity) still intelligence? When an ant makes a left turn, does the ant behind it make an intelligent decision to follow suit? Or when it rains, is a tree intelligent in its choice to flip over its leaves? These kinds of questions must be answered before we are ready to pin down a useful definition of the term &ldquo;artificial intelligence&rdquo;.</p><p>The Humian exposé of our misled cause-and-effect model of reality could be extended to bare a dubious interpretation of intelligence as “the thing which happens in between the cause and effect". Though, the acclaimed linear premise itself is already questionable. It seems to me there’s more to intelligence than what meets the eye — the solipsist nature of the concept makes it a tough nut to crack.</p><h1 id=some-conjecture>some conjecture</h1><p>What happens when we grant an entity &ldquo;intelligence&rdquo;? Do we also grant it a kind of freedom, or an agency in creating its own perception and therefore its own reality? If this is the case, it should not be farfetched to say that granting intelligence is akin to granting the freedom to create an individualized code of ethics.<sup id=fnref:5><a href=#fn:5 class=footnote-ref role=doc-noteref>5</a></sup> Indeed, there are of course issues that could arise were we to allow an automaton to create its own system of ethics, but the alternative is not without error. For example, consider Isaac Asimov&rsquo;s Three Laws of Robotics, made immortal from his science fiction short story <em>&ldquo;Runaround&rdquo;</em> (featured in the popular 1950 collection <em>&ldquo;I, Robot&rdquo;</em>):</p><ol><li>A robot may not injure a human being or, through inaction, allow a human being to come to harm.</li><li>A robot must obey the orders given it by human beings except where such orders would conflict with the First Law.</li><li>A robot must protect its own existence as long as such protection does not conflict with the First or Second Law.</li></ol><p>The interesting thing about these laws is they seem consistent in themselves, yet the whole point of the stories for which they were designed is to illustrate how these laws can lead to cataclysmic circumstances. Even in their design to create an ethical framework for automatons to act within, Asimov purposefully describes scenarios where these laws are insufficient for purely ethical behavior.</p><p>Is there a Gödelian argument to be made here, where if we cannot prove our own ethical consistency, then a recreation of our ethical system cannot guarantee avoidance of unethical behavior?</p><h1 id=back-to-reality>back to reality</h1><p>As it stands, we are not quite at a place technologically where these kinds of questions are relevant, on the contrary, most of the scientific world may consider the above discussion purely otiose. So, in an effort to practically and usefully define the term &ldquo;artificial intelligence&rdquo;, I&rsquo;d like to return to Russell & Norvig&rsquo;s definition, where AI is a <strong>field</strong> which aims to build one of the following: systems which think like humans, act like humans, think rationally, or act rationally. First, I believe that pinning down AI as a field, much like mathematics or psychology, is appropriate. Where AI as a product leads us down a path of immense subjectivity, AI as a field allows for flexibility, diversity, contribution, and of course evolution, while still being precise. That said, I think we need to adjust the terms of its aim.</p><p>Instead of keeping things discrete, where the meaning of &ldquo;thinks like&rdquo; or &ldquo;acts like&rdquo; may be met with conflicting interpretations, I propose we use a continuous scale. Consider the axes below:</p><figure class=center-image><img src=https://airport-people.com/ai_def.svg></figure><p>Simply, I&rsquo;d redefine AI to be <em>&ldquo;the field which aims to build systems whose nature can be represented as a point somewhere on this coordinate plane&rdquo;</em>.<sup id=fnref:6><a href=#fn:6 class=footnote-ref role=doc-noteref>6</a></sup> Or, for a travel-size version:</p><blockquote><p><em>AI is a field which produces a range of acting or reasoning entities.</em></p></blockquote><p>An entity or system which obtains the point at the origin is, roughly, not a good AI product; it does not reason or act — it is inert. One which obtains the point where the $x$-axis intersects the blue arc has a behavior indistinguishable from humans, and alternatively the point where the $y$-axis intersects the blue arc is the perfect candidate to play Turing&rsquo;s &ldquo;Imitation Game&rdquo; (colloquially known as &ldquo;The Turing Test&rdquo;). Further outside the arc implies something more and more ideal than humans, and further toward the origin implies something less and less ideal than humans.<sup id=fnref:7><a href=#fn:7 class=footnote-ref role=doc-noteref>7</a></sup></p><h1 id=conclusion>conclusion</h1><p>I hope the above definition helps us measure our products a bit more firmly. There&rsquo;s still a lot of work to be done in the field, so maybe its definition will change. But for now, this is my proposal as of March 2021.</p><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>Bringsjord, S. & Govindarajulu, N. Artificial Intelligence. Stanford Encyclopedia of Philosophy. 2018.&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p>Nevins, Daniel. Halakhic Responses to Artificial Intelligence and Autonomous Machines. 2019.&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:3><p>Russell, S. and Norvig, P. Artificial Intelligence: A Modern Approach (4th Edition). Pearson, 2020.&#160;<a href=#fnref:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:4><p>In <a href=https://arxiv.org/pdf/2104.12871.pdf>Why AI is Harder Than We Think</a>, Melanie Mitchell from The Santa Fe Institute provides an outstanding analysis of this question from the perspective of the shortcomings of &ldquo;AI&rdquo;. Of note is one particular observation she cites by Hans Moravec that even human <em>reason</em> (and, in turn, I assert, our confidence in logic) is dependent on purely biological, genetic, evolutionary knowledge about how to survive on earth.&#160;<a href=#fnref:4 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:5><p>Sure, there may be an element of universality in Ethics (where even a new intelligence must necessarily share, at least in part, the same ethical system as humans), but I do not pretend to exclude the possibility that new intelligences may stake claim to their own ethical system absolutely independent of our own.&#160;<a href=#fnref:5 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:6><p>In fact, this proposal vaguely echos the concept of orthogonality between intelligence and goals as described in Nick Bostrom&rsquo;s <em>Superintelligence: Paths, Dangers, Strategies</em>.&#160;<a href=#fnref:6 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:7><p>The term &ldquo;ideal&rdquo; is difficult here. Much like the indeterminate nature of the metaphysical and ontological ideal world, describing &ldquo;perfection&rdquo; in reasoning or acting must be all but impossible. For now, I&rsquo;ll leave it to the reader to contact me by <a href=mailto:airportpeoplemusic@gmail.com>email</a> if you have a better way to address the issue.&#160;<a href=#fnref:7 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></article><div class=pagination><a href=https://airport-people.com/blog/20201001/>&#171; prometheus and google</a>
<a href=https://airport-people.com/blog/20201220/>reinforcement learning and ethics &#187;</a></div></section><br></section></main><footer class="row middle-xs center-xs"><div class="col-xs-3 col-md-2"><a target=_blank rel=noopener href=https://airportpeople.bandcamp.com>bandcamp</a></div><div class="col-xs-3 col-md-2"><a target=_blank rel=noopener href=https://instagram.com/airportpeoplemusic>instagram</a></div><div class="col-xs-3 col-md-2"><a target=_blank rel=noopener href=https://github.com/airportpeople>github</a></div><div class=col-xs-12>copyright &copy; 2022 airport people.</div><script src=https://unpkg.com/littlefoot/dist/littlefoot.js type=application/javascript></script>
<script type=application/javascript>littlefoot.littlefoot({buttonTemplate:'<button                         aria-expanded="false"                         aria-label="Footnote <% number %>"                         class="littlefoot-footnote__button"                         id="<% reference %>"                         title="See Footnote <% number %>"                         style="background-color: transparent; margin: 5px 0 0 0; padding: 0px; vertical-align: top; text-align: center; font-weight: 200; color: #212121; font-size: .7em; min-width: 3px;"                      />                         <% number %>                       </button>'})</script></footer><div id=modal-4a3c class=modal><div class=modal-box><span class=close>&#215;</span><div class=modal-container><div class=modal-header><div class=modal-header-img-container style=background-color:#f7f7f7><img data-src=https://airport-people.com/images/lt_logo.png class=lazyload alt="this is some music"></div></div><div class=modal-content><h2>sync licensing</h2><article class=entry-content><h1 id=leaving-things>Leaving Things</h1><p>Sync licensing for film, dance, etc., is managed through <a href=https://leavingthings.com/artists-feed/airport-people>Leaving Things</a>.</p><p>Leaving Things Music Sync Licensing works with a tightly curated group of experimental musicians to foster connections between visual creatives looking for songs, custom compositions, and sounds that are engaging, unique and left-of-center.</p></article><h3><a href=https://leavingthings.com/artists-feed/airport-people>⭢</a></h3></div></div></div></div><div id=modal-ec60 class=modal><div class=modal-box><span class=close>&#215;</span><div class=modal-container><div class=modal-header><div class=modal-header-img-container style=background-color:#f7f7f7><img data-src=https://airport-people.com/images/bc_logo.svg class=lazyload alt="this is some music"></div></div><div class=modal-content><h2>bandcamp</h2><article class=entry-content><p>All music and merch are managed on <a href=https://airportpeople.bandcamp.com/>Bandcamp</a>.</p></article><h3><a href=https://airportpeople.bandcamp.com/>⭢</a></h3></div></div></div></div><div id=modal-b51e class=modal><div class=modal-box><span class=close>&#215;</span><div class=modal-container><div class=modal-header><div class=modal-header-img-container style=background-color:#f7f7f7><img data-src=https://airport-people.com/images/uda_art.jpeg class=lazyload alt="this is some music"></div></div><div class=modal-content><h2>recent release</h2><article class=entry-content><h1 id=underscore-dash-apostrophe>underscore dash apostrophe</h1><p>A study in subtlety, I suppose.</p></article><h3><a href=https://airportpeople.bandcamp.com/track/underscore-dash-apostrophe>⭢</a></h3></div></div></div></div><div id=modal-bd84 class=modal><div class=modal-box><span class=close>&#215;</span><div class=modal-container><div class=modal-header><div class=modal-header-img-container style=background-color:#f7f7f7><img data-src=https://airport-people.com/images/the_underscore.jpeg class=lazyload alt="this is some music"></div></div><div class=modal-content><h2>recent release</h2><article class=entry-content><h1 id=the-underscore>the underscore</h1><p>This is a distillation of melody from a previous release, <em>underscore dash apostrophe.</em></p></article><h3><a href=https://airportpeople.bandcamp.com/album/the-underscore>⭢</a></h3></div></div></div></div><script src=https://airport-people.com/js/src/modal.min.b1f2588607a4108a9f5c79d672b8efc3c542e2256ffe465b5ae04fdb39713ea4.js type=text/javascript></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js></script>
<script>hljs.initHighlightingOnLoad()</script><script src=https://airport-people.com/js/src/main.min.2eb0efba04f9d46cd2be0d81caa4f00de5b2ba8295e0fff3220fe4b02edf1e36.js type=text/javascript></script></body></html>