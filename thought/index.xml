<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>thought on airport people</title><link>https://airportpeople.github.io/thought/</link><description>Recent content in thought on airport people</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sat, 12 Sep 2020 17:54:20 +0000</lastBuildDate><atom:link href="https://airportpeople.github.io/thought/index.xml" rel="self" type="application/rss+xml"/><item><title>anthropomorphization of algorithms</title><link>https://airportpeople.github.io/thought/20210613/</link><pubDate>Sun, 13 Jun 2021 12:21:06 +0000</pubDate><guid>https://airportpeople.github.io/thought/20210613/</guid><description>motivation Daily human life is becoming increasingly intertwined with algorithms. The people who develop these algorithms (and, to a lesser extent, the implicit users of these algorithms — the general public) can only use their native languages to describe algorithmic nature and activity. E.g., &amp;ldquo;Netflix is recommending this movie to me&amp;rdquo;, &amp;ldquo;my Tesla is looking ahead to find obstructions blocking our path&amp;rdquo;, or &amp;ldquo;the software loading wheel indicates the computer is thinking&amp;rdquo;.</description></item><item><title>on hume’s deontological response to scepticism</title><link>https://airportpeople.github.io/thought/20210204/</link><pubDate>Thu, 04 Feb 2021 21:07:30 +0000</pubDate><guid>https://airportpeople.github.io/thought/20210204/</guid><description>introduction In Hume’s Deontological Response to Scepticism (HDRS), Hsueh Qu from the National University of Singapore provides a novel interpretation of Hume’s take on the sceptical system of philosophy.1 At the end of Part IV of A Treatise of Human Nature, Book I (THN 1.4), Hume illustrates the Dangerous Dilemma bound to befall anyone deeply considering a sceptical outlook on their world: if we are to remain sceptical of all things, we must be sceptical of (and may condemn) all reasoning, which is devastative, and if we then avoid scepticism altogether, we are reduced to credulity, of which we should only be ashamed — in his words, we have “no choice left but betwixt a false reason and none at all”.</description></item><item><title>reinforcement learning and ethics</title><link>https://airportpeople.github.io/thought/20201220/</link><pubDate>Sun, 20 Dec 2020 17:02:58 +0000</pubDate><guid>https://airportpeople.github.io/thought/20201220/</guid><description>introduction In the short film Perfectly Natural, we see a young couple, their new baby, and a simulated reality where the baby interacts with her artificially programmed parents. Over the course of this film’s fourteen minutes, we see a familiar thread of theoretical interactions between humans and their artificially intelligent counterparts. First, there is an apparent excitement from experiencing something new and fantastic, then a series of routine correspondence, and finally a hint of mortal obsoletion.</description></item><item><title>defining ai</title><link>https://airportpeople.github.io/thought/20201212/</link><pubDate>Sat, 12 Dec 2020 21:16:44 +0000</pubDate><guid>https://airportpeople.github.io/thought/20201212/</guid><description>introduction In the summer of 1956, Dartmouth College held its first Summer Research Project on Artificial Intelligence to discuss developments in a new field called (and there coined) “artificial intelligence.” But, the idea of thinking mechanical agents was made clear in earlier texts such as Alan Turing’s seminal work Computing Machinery and Intelligence (1950), and even as early as 1637, when Descartes implied a requirement for some test by which we may distinguish between humans and machines that act human-like.</description></item><item><title>prometheus and google</title><link>https://airportpeople.github.io/thought/20201001/</link><pubDate>Thu, 01 Oct 2020 13:01:31 +0000</pubDate><guid>https://airportpeople.github.io/thought/20201001/</guid><description>introduction In creating media based on myths, symbols, and idols, we may lose the value and meaning of the original if recommender systems and search algorithms do not find a harmonic balance between meaning and object. The burden lies on the recommender to recognize the difference between the &amp;ldquo;common&amp;rdquo; media definition and some other potentially more pure definition or connotation. Whether the former is any more appropriate than the latter is also investigated, along with a generalized form of this phenomenon, comparing words as they exist on common search/recommendation engines, and the same words when they connote other (prior or &amp;ldquo;purer&amp;rdquo;) concepts.</description></item><item><title>premise and purpose</title><link>https://airportpeople.github.io/thought/20200928/</link><pubDate>Mon, 28 Sep 2020 21:09:13 +0000</pubDate><guid>https://airportpeople.github.io/thought/20200928/</guid><description>a start In my attempts at curating a repository of admittedly amateur philosophical essays, I find myself fairly challenged when trying to form a pure foundation of premises and axioms. It seems to me that any philosophy must start with a consistent set of premises or at least an intuitively sound few axioms to work from. Otherwise, the goal must be to engage with or potentially critique the established work of one&amp;rsquo;s self or another — at least in as much as something fruitful may come from compounding one&amp;rsquo;s work on that of another.</description></item><item><title>artificial neural networks</title><link>https://airportpeople.github.io/thought/20180701/</link><pubDate>Sun, 01 Jul 2018 21:09:13 +0000</pubDate><guid>https://airportpeople.github.io/thought/20180701/</guid><description>redirection In 2018, I wrote an extended white paper on the architecture and theory behind Artificial Neural Networks. This paper currently exists only in PDF format. You can read it here.</description></item></channel></rss>