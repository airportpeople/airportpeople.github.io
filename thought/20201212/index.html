<!doctype html><html><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="chrome=1"><meta name=HandheldFriendly content="True"><meta name=MobileOptimized content="320"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><meta name=description content="Minimalist music and accompanying thoughts."><title>defining ai - airport people</title><link rel="shortcut icon" href=/circle.ico><link rel=stylesheet href=/css/main.min.0beda6c039f843069d18546dafc5f7cd281c5bb1492eaa21fbb7d21c6975abd1.css integrity="sha256-C+2mwDn4QwadGFRtr8X3zSgcW7FJLqoh+7fSHGl1q9E=" crossorigin=anonymous media=screen><link rel=stylesheet href=https://airportpeople.github.io/css/photoswipe.css><link rel=stylesheet href=https://airportpeople.github.io/css/default-skin.css><link rel=preconnect href=https://fonts.gstatic.com><link href="https://fonts.googleapis.com/css2?family=Cormorant+Infant:ital,wght@0,300;0,500;1,300;1,500&family=Italiana&display=swap" rel=stylesheet><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://airportpeople.github.io/tn.png"><meta name=twitter:title content="defining ai"><meta name=twitter:description content="introduction In the summer of 1956, Dartmouth College held its first Summer Research Project on Artificial Intelligence to discuss developments in a new field called (and there coined) “artificial intelligence.” But, the idea of thinking mechanical agents was made clear in earlier texts such as Alan Turing’s seminal work Computing Machinery and Intelligence (1950), and even as early as 1637, when Descartes implied a requirement for some test by which we may distinguish between humans and machines that act human-like."><meta property="og:title" content="defining ai"><meta property="og:description" content="introduction In the summer of 1956, Dartmouth College held its first Summer Research Project on Artificial Intelligence to discuss developments in a new field called (and there coined) “artificial intelligence.” But, the idea of thinking mechanical agents was made clear in earlier texts such as Alan Turing’s seminal work Computing Machinery and Intelligence (1950), and even as early as 1637, when Descartes implied a requirement for some test by which we may distinguish between humans and machines that act human-like."><meta property="og:type" content="article"><meta property="og:url" content="https://airportpeople.github.io/thought/20201212/"><meta property="og:image" content="https://airportpeople.github.io/tn.png"><meta property="article:published_time" content="2020-12-12T21:16:44+00:00"><meta property="article:modified_time" content="2020-12-12T21:16:44+00:00"><meta property="og:site_name" content="airport people"><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-109890414-1','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css integrity=sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js integrity=sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js integrity=sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:true},{left:"$",right:"$",display:false}]});});</script><link rel=stylesheet href=https://unpkg.com/littlefoot/dist/littlefoot.css><title>defining ai</title></head><body><header class="wrap flex-container"><h1>defining ai</h1></header><main class=wrap><article role=article class=flex-container><h1 id=introduction>introduction</h1><p>In the summer of 1956, Dartmouth College held its first Summer Research Project on Artificial Intelligence to discuss developments in a new field called (and there coined) “artificial intelligence.” But, the idea of thinking mechanical agents was made clear in earlier texts such as Alan Turing’s seminal work Computing Machinery and Intelligence (1950), and even as early as 1637, when Descartes implied a requirement for some test by which we may distinguish between humans and machines that act human-like.<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup> Even further, Rabbi Daniel Nevins<sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup> illustrates how the ancient folkloric notion of a golem can be interpreted as a theoretical creature with some sort of artificial (limited) intelligence. Ostensibly, AI is an old compelling idea, and it goes by many names and forms, so pinning down a useful comprehensive definition is an increasingly difficult task.</p><h1 id=colloquially>colloquially</h1><p>Today, the phrase “artificial intelligence” (AI) is used in so many ways that it is all but rendered meaningless. It is used to describe image recognition algorithms, text generation, chat-bots, linear regression, artificial neural networks, topic models, etc. Russell & Norvig use a goal-based definition,<sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup> implying AI is the &ldquo;field that aims at building&rdquo; systems which think (or act) like humans, or systems which think (or act) rationally. Often, the tech and robotics industries use the term to inculcate in their users a sense that their product is accomplishing something technologically sexy. But, I for one am not convinced we are ready to define artificial intelligence any more than we are equipped to define intelligence itself. Is intelligence a purely human trait, or is it universal? Is limited intelligence (e.g., stupidity) still intelligence? When an ant makes a left turn, does the ant behind it make an intelligent decision to follow suit? Or when it rains, is a tree intelligent in its choice to flip over its leaves? These kinds of questions must be answered before we are ready to pin down a useful definition of the term &ldquo;artificial intelligence&rdquo;.</p><p>The Humian exposé of our misled cause-and-effect model of reality could be extended to bare a dubious interpretation of intelligence as “the thing which happens in between the cause and effect&rdquo;. Though, the acclaimed linear premise itself is already questionable. It seems to me there’s more to intelligence than what meets the eye — the solipsist nature of the concept makes it a tough nut to crack.</p><h1 id=some-conjecture>some conjecture</h1><p>What happens when we grant an entity &ldquo;intelligence&rdquo;? Do we also grant it a kind of freedom, or an agency in creating its own perception and therefore its own reality? If this is the case, it should not be farfetched to say that granting intelligence is akin to granting the freedom to create an individualized code of ethics.<sup id=fnref:4><a href=#fn:4 class=footnote-ref role=doc-noteref>4</a></sup> Indeed, there are of course issues that could arise were we to allow an automaton to create its own system of ethics, but the alternative is not without error. For example, consider Isaac Asimov&rsquo;s Three Laws of Robotics, made immortal from his science fiction short story <em>&ldquo;Runaround&rdquo;</em> (featured in the popular 1950 collection <em>&ldquo;I, Robot&rdquo;</em>):</p><ol><li>A robot may not injure a human being or, through inaction, allow a human being to come to harm.</li><li>A robot must obey the orders given it by human beings except where such orders would conflict with the First Law.</li><li>A robot must protect its own existence as long as such protection does not conflict with the First or Second Law.</li></ol><p>The interesting thing about these laws is they seem consistent in themselves, yet the whole point of the stories for which they were designed is to illustrate how these laws can lead to cataclysmic circumstances. Even in their design to create an ethical framework for automatons to act within, Asimov purposefully describes scenarios where these laws are insufficient for purely ethical behavior.</p><p>Is there a Gödelian argument to be made here, where if we cannot prove our own ethical consistency, then a recreation of our ethical system cannot guarantee avoidance of unethical behavior?</p><h1 id=back-to-reality>back to reality</h1><p>As it stands, we are not quite at a place technologically where these kinds of questions are relevant, on the contrary, most of the scientific world may consider the above discussion purely otiose. So, in an effort to practically and usefully define the term &ldquo;artificial intelligence&rdquo;, I&rsquo;d like to return to Russell & Norvig&rsquo;s definition, where AI is a <strong>field</strong> which aims to build one of the following: systems which think like humans, act like humans, think rationally, or act rationally. First, I believe that pinning down AI as a field, much like mathematics or psychology, is appropriate. Where AI as a product leads us down a path of immense subjectivity, AI as a field allows for flexibility, diversity, contribution, and of course evolution, while still being precise. That said, I think we need to adjust the terms of its aim.</p><p>Instead of keeping things discrete, where the meaning of &ldquo;thinks like&rdquo; or &ldquo;acts like&rdquo; may be met with conflicting interpretations, I propose we use a continuous scale. Consider the axes below:</p><figure class=center-image><img src=/ai_def.svg></figure><p>Simply, I&rsquo;d redefine AI to be <em>&ldquo;the field which aims to build systems whose nature can be represented as a point somewhere on this coordinate plane&rdquo;</em>. Or, maybe more succinctly <em>&ldquo;any product of AI can be represented as a point on this plane."</em></p><p>A system which obtains the point at the origin is, roughly, not a good AI product. One which obtains the point where the $x$-axis intersects the blue circle has a behavior indistinguishable from humans, and alternatively the point where the $y$-axis intersects the blue circle is the perfect candidate for the Turing Test. Further outside the circle implies something more and more ideal than humans, and further toward the origin implies something less and less ideal than humans.<sup id=fnref:5><a href=#fn:5 class=footnote-ref role=doc-noteref>5</a></sup></p><h1 id=conclusion>conclusion</h1><p>I hope this definition helps us measure our products a bit more firmly. There&rsquo;s still a lot of work to be done in the field, so maybe its definition will change. But for now, this is my proposal.</p><section class=footnotes role=doc-endnotes><hr><ol><li id=fn:1 role=doc-endnote><p>Bringsjord, S. & Govindarajulu, N. Artificial Intelligence. Stanford Encyclopedia of Philosophy. 2018. <a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2 role=doc-endnote><p>Nevins, Daniel. Halakhic Responses to Artificial Intelligence and Autonomous Machines. 2019. <a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:3 role=doc-endnote><p>Russell, S. and Norvig, P. Artificial Intelligence: A Modern Approach (4th Edition). Pearson, 2020. <a href=#fnref:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:4 role=doc-endnote><p>Sure, there may be an element of universality in Ethics (where even a new intelligence must necessarily share, at least in part, the same ethical system as humans), but I do not pretend to exclude the possibility that new intelligences may stake claim to their own ethical system absolutely independent of our own. <a href=#fnref:4 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:5 role=doc-endnote><p>The term &ldquo;ideal&rdquo; is difficult here. Much like the indeterminate nature of the metaphysical and ontological ideal world, describing &ldquo;perfection&rdquo; in reasoning or acting must be all but impossible. For now, I&rsquo;ll leave it to the reader to contact me if you have a better way to address the issue. <a href=#fnref:5 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></section></article><nav role=navigation class="flex-container bottom-menu"><hr><p><a href=/music>music</a>
&#183;
<a href=/fyi>for</a>
&#183;
<a href=/thought>thought</a>
&#183;
<a href=/about>.ap.</a>
&#183;
<a href=/>main</a></p></nav></main><footer class="flex-container footer"><div id=mc_embed_signup><form action="https://airport-people.us2.list-manage.com/subscribe/post?u=8cb6aff1486d45a62e44eeeaf&id=423bf227db" method=post id=mc-embedded-subscribe-form name=mc-embedded-subscribe-form class=validate target=_blank novalidate><div id=mc_embed_signup_scroll><div class=mc-field-group><input type=email name=EMAIL class="required email" id=mce-EMAIL placeholder="email address"></div><div id=mce-responses class=clear><div class=response id=mce-error-response style=display:none></div><div class=response id=mce-success-response style=display:none></div></div><div style=position:absolute;left:-5000px aria-hidden=true><input type=text name=b_8cb6aff1486d45a62e44eeeaf_423bf227db tabindex=-1></div><div class=clear><input type=submit value=subscribe name=subscribe id=mc-embedded-subscribe class=button></div></div></form></div>music for .thought. for music
<script src=https://unpkg.com/littlefoot/dist/littlefoot.js type=application/javascript></script><script type=application/javascript>littlefoot.littlefoot({buttonTemplate:'<button \
                      aria-expanded="false" \
                      aria-label="Footnote <% number %>" \
                      class="littlefoot-footnote__button" \
                      id="<% reference %>" \
                      title="See Footnote <% number %>" \
                      style="background-color: transparent; margin: 5px 0 0 0; padding: 0px; vertical-align: top; text-align: center; font-weight: 200; color: #16264c; font-size: .7em; min-width: 3px;"\
                    /> \
                      <% number %> \
                    </button>'})</script></footer></body></html>